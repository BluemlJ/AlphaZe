{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of an evaluation based on the MCTSAgent\n",
    "\n",
    "This notebook uses the configuration file at `CrazyAra/DeepCrazyhouse/configs/main_config.py`\n",
    "for loading the neural network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.variant\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'../../../')\n",
    "from DeepCrazyhouse.src.runtime.color_logger import enable_color_logging\n",
    "from DeepCrazyhouse.src.domain.agent.neural_net_api import NeuralNetAPI\n",
    "from DeepCrazyhouse.src.domain.agent.player.mcts_agent import MCTSAgent\n",
    "from DeepCrazyhouse.src.domain.agent.player.raw_net_agent import RawNetAgent\n",
    "from DeepCrazyhouse.src.domain.variants.game_state import GameState\n",
    "from DeepCrazyhouse.src.runtime.color_logger import enable_color_logging\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "enable_color_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "threads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the neural network\n",
    "Change `ctx='cpu'` into `ctx='gpu'` if you have a nvidia gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = []\n",
    "for idx in range(2):\n",
    "    nets.append(NeuralNetAPI(ctx='cpu', batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_agent = RawNetAgent(nets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_movetime = 10000\n",
    "mcts_agent = MCTSAgent(nets, threads=threads,\n",
    "                       playouts_empty_pockets=4096*5, playouts_filled_pockets=4096*5,\n",
    "                       cpuct=2.5, u_init_divisor=0.25, dirichlet_epsilon=.25, dirichlet_alpha=0.2,\n",
    "                       batch_size=batch_size, q_value_weight=0.7, max_search_depth=40, temperature=.07,\n",
    "                       virtual_loss=3, verbose=True, temperature_moves=0, enhance_checks=True,\n",
    "                       min_movetime=min_movetime, use_pruning=False, opening_guard_moves=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of board position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.variant.CrazyhouseBoard()\n",
    "\n",
    "# you can either push a sequence of moves\n",
    "#board.push_uci('e2e4')\n",
    "#board.push_uci('e7e6')\n",
    "\n",
    "# or set a fen position directly\n",
    "# Test positions\n",
    "#fen = '3R1b2/1bP1kp2/3Npn1p/3p4/5p2/5N1b/PPP1QP1P/3R1RK1/QPpprnpbp b - - 0 29'\n",
    "fen = 'rn2N2k/pp5p/3pp1pN/3p4/3q1P2/3P1p2/PP3PPP/RN3RK1[Qrbbpbb] b - - 3 30' # d4f2 is winning\n",
    "#fen ='2kr1b2/1bp2p1p/p3pP1p/1p5Q/5B2/3B1p2/PPP2PrP/R4R1K/QNpnnnp w - - 0 18'\n",
    "#fen = 'r1bq1b1r/ppp1kPpp/4Pn2/n2Pp3/2B4n/3P4/PPP2PPP/RNBQK2R/ w KQ - 0 10'\n",
    "#fen = '3rkb1r/2pb1pp1/q2Pp3/3pP2p/3P4/2PPnP2/P1P1N1PP/R2R2K1/NNQbb b k - 0 21' # mate threat from JannLee game\n",
    "\n",
    "board.set_fen(fen)\n",
    "\n",
    "state = GameState(board)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(state.get_legal_moves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_moves_with_prob(moves, probs, only_top_x=None):\n",
    "    \n",
    "    # revert the ordering afterwards\n",
    "    idx_order = np.argsort(probs)[::-1]\n",
    "    \n",
    "    if only_top_x is not None and only_top_x < len(idx_order):\n",
    "        idx_order = idx_order[:only_top_x]\n",
    "    \n",
    "    #moves_ordered = moves[range(len(moves))] #idx_order[::-1]]\n",
    "    probs_ordered = [] #probs[idx_order]\n",
    "    \n",
    "    moves_ordered = []\n",
    "    for idx in idx_order:\n",
    "        probs_ordered.append(probs[idx])\n",
    "        moves_ordered.append(moves[idx])\n",
    "        \n",
    "    plt.barh(range(len(probs_ordered)), probs_ordered)\n",
    "    plt.yticks(range(len(moves_ordered)), moves_ordered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalution using the raw network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_s = time()\n",
    "pred_value, legal_moves, p_vec_small, cp, depth, nodes, time_elapsed_s, nps, pv = raw_agent.evaluate_board_state(state)\n",
    "print('Elapsed time: %.4fs' % (time()-t_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value evaluation\n",
    "Value is always returned with respect to the current player to move.\n",
    "\n",
    "Therefore, if it's black's turn to move and the eval is positive then it assumes an advantage for the black player.\n",
    "* `cp` is a conversion into centi-pawn metric. +100 cp means an advantage of 1 pawn.\n",
    "* `pred_value` is the original predicted value ranging from [-1,+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw network policy\n",
    "This policy return is deterministic for a specific neural network weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moves_with_prob(legal_moves, p_vec_small, only_top_x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalution using the MCTS-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_s = time()\n",
    "pred_value, legal_moves, p_vec_small, cp, depth, nodes, time_elapsed_s, nps, pv = mcts_agent.evaluate_board_state(state)\n",
    "print('Elapsed time: %.4fs' % (time()-t_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for the policy, visits and Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moves_with_prob(legal_moves, p_vec_small, only_top_x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moves_with_prob(legal_moves, mcts_agent.root_node.child_number_visits, only_top_x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moves_with_prob(legal_moves, mcts_agent.root_node.q_value, only_top_x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
