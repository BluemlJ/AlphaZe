{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training script for the CNN \n",
    "\n",
    "Loads in the converted plane representation of the pgn files, defines the network architecture and starts the training process. Checkpoints of the weights are saved if there's an improvement in the validation loss.\n",
    "The training performance metrics (e.g. losses, accuracies...) are exported to tensorboard and can be checked during training.\n",
    "* author: QueensGambit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.insert(0,'../../../')\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import chess\n",
    "import random\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook\n",
    "from mxnet import nd, autograd\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from multiprocessing import cpu_count\n",
    "from time import time\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd as ag\n",
    "from mxboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from DeepCrazyhouse.src.domain.variants.input_representation import board_to_planes, planes_to_board\n",
    "from DeepCrazyhouse.src.domain.variants.output_representation import policy_to_moves, policy_to_best_move, policy_to_move\n",
    "from DeepCrazyhouse.src.preprocessing.dataset_loader import load_pgn_dataset\n",
    "from DeepCrazyhouse.src.runtime.color_logger import enable_color_logging\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.a0_resnet import AlphaZeroResnet\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.mxnet_alpha_zero import alpha_zero_symbol\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.rise_mobile_symbol import rise_mobile_symbol, preact_resnet_symbol\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.rise import Rise\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.densenet import DenseNet\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.wide_resnet_se import WideResnetSE\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.shuffle_rise import ShuffleRise\n",
    "from DeepCrazyhouse.src.preprocessing.pgn_record_dataset import PGNRecordDataset\n",
    "from DeepCrazyhouse.configs.main_config import main_config\n",
    "from DeepCrazyhouse.configs.main_config import main_config\n",
    "from DeepCrazyhouse.src.training.trainer_agent import TrainerAgent, evaluate_metrics, acc_sign, reset_metrics\n",
    "from DeepCrazyhouse.src.training.trainer_agent_mxnet import TrainerAgentMXNET\n",
    "from DeepCrazyhouse.src.training.lr_schedules.lr_schedules import *\n",
    "from DeepCrazyhouse.src.domain.variants.plane_policy_representation import FLAT_PLANE_IDX\n",
    "from DeepCrazyhouse.src.domain.variants.constants import NB_POLICY_MAP_CHANNELS, NB_LABELS\n",
    "\n",
    "enable_color_logging()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the context on CPU, switch to GPU if there is one available (strongly recommended for training)\n",
    "ctx = mx.gpu(0) #2\n",
    "# set a specific seed value for reproducability\n",
    "seed = 42\n",
    "\n",
    "export_weights = True\n",
    "log_metrics_to_tensorboard = True\n",
    "export_grad_histograms = True\n",
    "div_factor = 1\n",
    "\n",
    "# batch_steps = 1000 means for example that every 1000 batches the validation set gets processed\n",
    "batch_steps = 1000 * div_factor # this defines how often a new checkpoint will be saved and the metrics evaluated\n",
    "# k_steps_initial defines how many steps have been trained before\n",
    "# (k_steps_initial != 0 if you continue training from a checkpoint)\n",
    "k_steps_initial = 0\n",
    "cur_it = k_steps_initial * batch_steps # iteration counter used for the momentum and learning rate schedule\n",
    "# these are the weights to continue training with\n",
    "symbol_file = None\n",
    "params_file = None\n",
    "\n",
    "batch_size = 1024 // div_factor # 1024 # the batch_size needed to be reduced to 1024 in order to fit in the GPU 1080Ti\n",
    "#4096 was originally used in the paper -> works slower for current GPU\n",
    "# 2048 was used in the paper Mastering the game of Go without human knowledge and fits in GPU memory\n",
    "#typically if you half the batch_size, you should double the lr\n",
    "\n",
    "# optimization parameters\n",
    "optimizer_name = \"nag\"\n",
    "max_lr = 0.35 / div_factor #0.01 # default lr for adam\n",
    "min_lr = 0.00001\n",
    "max_momentum = 0.95\n",
    "min_momentum = 0.8\n",
    "# loads a previous checkpoint if the loss increased significanly\n",
    "use_spike_recovery = True\n",
    "# stop training as soon as max_spikes has been reached\n",
    "max_spikes = 20\n",
    "# define spike threshold when the detection will be triggered\n",
    "spike_thresh = 1.5\n",
    "# weight decay\n",
    "wd = 1e-4\n",
    "dropout_rate = 0.2\n",
    "# weight the value loss a lot lower than the policy loss in order to prevent overfitting\n",
    "val_loss_factor = 0.01\n",
    "policy_loss_factor = 0.99\n",
    "discount = 1.0 # 0.995\n",
    "\n",
    "normalize = True # define whether to normalize input data to [0,1]\n",
    "nb_epochs = 7 # define how many epoches the network will be trained\n",
    "\n",
    "select_policy_from_plane = True # Boolean if potential legal moves will be selected from final policy output\n",
    "use_mxnet_style = True # Decide between mxnet and gluon style for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixing the random seed\n",
    "mx.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ./logs and ./weights directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./logs && mkdir ./weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPU_COUNT = cpu_count()//2\n",
    "#if use_mxnet_style:\n",
    "#    os.environ[\"MXNET_CPU_WORKER_NTHREADS\"] = str(CPU_COUNT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the dataset-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataset (which is used during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idcs_val, x_val, yv_val, yp_val, plys_to_end, pgn_datasets_val = load_pgn_dataset(dataset_type='val', part_id=0,\n",
    "                                                                           print_statistics=True, print_parameters=True, normalize=normalize)\n",
    "if discount != 1:\n",
    "    yv_val *= discount**plys_to_end\n",
    "if use_mxnet_style:\n",
    "    if select_policy_from_plane:\n",
    "        val_iter = mx.io.NDArrayIter({'data': x_val}, {'value_label': yv_val, 'policy_label': np.array(FLAT_PLANE_IDX)[yp_val.argmax(axis=1)]}, batch_size)\n",
    "    else:\n",
    "        val_iter = mx.io.NDArrayIter({'data': x_val}, {'value_label': yv_val, 'policy_label': yp_val.argmax(axis=1)}, batch_size)\n",
    "else:\n",
    "    val_dataset = gluon.data.ArrayDataset(nd.array(x_val), nd.array(yv_val), nd.array(yp_val.argmax(axis=1)))\n",
    "    val_data = gluon.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_parts = len(glob.glob(main_config['planes_train_dir'] + '**/*'))\n",
    "nb_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_it_per_epoch = (len(x_val) * nb_parts) // batch_size # calculate how many iterations per epoch exist\n",
    "# one iteration is defined by passing 1 batch and doing backprop\n",
    "total_it = int(nb_it_per_epoch * nb_epochs)\n",
    "total_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learning Rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = OneCycleSchedule(start_lr=max_lr/8, max_lr=max_lr, cycle_length=total_it*.3, cooldown_length=total_it*.6, finish_lr=min_lr)\n",
    "lr_schedule = LinearWarmUp(lr_schedule, start_lr=min_lr, length=total_it/30)\n",
    "plot_schedule(lr_schedule, iterations=total_it)\n",
    "#lr_schedule = ConstantSchedule(min_lr)\n",
    "#plot_schedule(lr_schedule, iterations=total_it, ylim=[-min_lr, max_lr*1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "momentum_schedule = MomentumSchedule(lr_schedule, min_lr, max_lr, min_momentum, max_momentum)\n",
    "#momentum_schedule = ConstantSchedule(min_momentum)\n",
    "plot_schedule(momentum_schedule, iterations=total_it, ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = x_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del net\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net = gluon.nn.SymbolBlock.imports(symbol_file='weights/%s'%symbol_file, input_names='data', param_file='weights/%s'%params_file, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = AlphaZeroResnet(n_labels=2272, channels=256, channels_value_head=8, channels_policy_head=81, num_res_blocks=19, value_fc_size=256, bn_mom=0.9, act_type='relu', select_policy_from_plane=select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#et = alpha_zero_resnet(n_labels=2272, channels=256, channels_value_head=1, channels_policy_head=81, num_res_blocks=19, value_fc_size=256, bn_mom=0.9, act_type='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expand_res_blocks=[3,3,3,5,5,5,5,5,7,7,7,7,7]\n",
    "#expand_res_blocks=[3,3,7,7,7]\n",
    "#net = Rise(n_labels=yp_val.shape[1], channels=256, channels_value_head=8, channels_policy_head=81, nb_res_blocks_x=0, nb_res_blocks_x_neck=0, expand_res_blocks=expand_res_blocks, value_fc_size=256, bn_mom=0.9, act_type='relu', squeeze_excitation_type=\"cSE\", select_policy_from_plane=select_policy_from_plane, use_rise_stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = DenseNet(channels_init=64, growth_rate=24, n_layers=7, bottleneck_factor=4, n_labels=yp_val.shape[1], channels_value_head=4, channels_policy_head=8, value_fc_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net = WideResnetSE(n_labels=yp_val.shape[1], channels=512, channels_value_head=4, channels_policy_head=8, nb_res_blocks=6, value_fc_size=512, bn_mom=0.9, act_type='relu', use_se=True, use_rise_stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = ShuffleRise(n_labels=yp_val.shape[1], channels=64, channels_value_head=4, channels_policy_head=81, nb_res_blocks_x=0, nb_shuffle_blocks=19, nb_shuffle_blocks_neck=0, value_fc_size=256, bn_mom=0.9, act_type='lrelu', squeeze_excitation_type=None, select_policy_from_plane=select_policy_from_plane, use_rise_stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = PyramidResnetSE(n_labels=2272, channels=256,  channels_value_head=1, channels_policy_head=81, num_res_blocks=19, value_fc_size=256,  bn_mom=0.9, act_type='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#symbol = alpha_zero_symbol(num_filter=256, channels_value_head=4, channels_policy_head=8, workspace=1024, value_fc_size=256, num_res_blocks=7, bn_mom=0.9, act_type='relu',\n",
    "#                            n_labels=2272, grad_scale_value=0.01, grad_scale_policy=0.99, select_policy_from_plane=select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc_res_blocks = [3]+[5]+[7]+[5]+[3]*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol = rise_mobile_symbol(channels=256, channels_operating_init=128, channel_expansion=64, channels_value_head=4,\n",
    "                   channels_policy_head=NB_POLICY_MAP_CHANNELS, value_fc_size=256, bc_res_blocks=bc_res_blocks, res_blocks=[], act_type='relu',\n",
    "                   n_labels=NB_LABELS, grad_scale_value=0.01, grad_scale_policy=0.99, select_policy_from_plane=select_policy_from_plane,\n",
    "                   use_se=True, dropout_rate=dropout_rate)\n",
    "#    symbol = mx.sym.load(\"weights/\" + symbol_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#symbol =preact_resnet_symbol(channels=256, channels_value_head=4,\n",
    "#                   channels_policy_head=81, value_fc_size=256, value_kernelsize=7,res_blocks=19,\n",
    "#                   act_type='relu', n_labels=2272, grad_scale_value=0.01, grad_scale_policy=0.99,\n",
    "#                   select_policy_from_plane=select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "symbol = preact_resnet_symbol(channels=256, channels_value_head=8,\n",
    "                   channels_policy_head=81, value_fc_size=256, res_blocks=19, act_type='relu',\n",
    "                   n_labels=4992, grad_scale_value=0.01, grad_scale_policy=0.99, select_policy_from_plane=True)\n",
    "if symbol_file:\n",
    "    symbol = mx.sym.load(\"weights/\" + symbol_file)\n",
    "    # probably change 'policy_loss_factor' and 'val_loss_factor'\n",
    "    #value_out = symbol.get_internals()['value_out_output']\n",
    "    #policy_out = symbol.get_internals()['policy_out_output']\n",
    "    #sym = mx.symbol.Group([value_out, policy_out])\n",
    "    #policy_out = mx.sym.SoftmaxOutput(data=policy_out, name='policy', grad_scale=policy_loss_factor)\n",
    "    #value_out = mx.sym.LinearRegressionOutput(data=value_out, name='value', grad_scale=val_loss_factor)\n",
    "\n",
    "    # group value_out and policy_out together\n",
    "    #symbol = mx.symbol.Group([value_out, policy_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not use_mxnet_style:\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_mxnet_style:\n",
    "    display(mx.viz.plot_network(\n",
    "        symbol,\n",
    "        shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "        node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}\n",
    "    ))\n",
    "else:\n",
    "    display(mx.viz.plot_network(\n",
    "        net(mx.sym.var('data'))[1],\n",
    "        shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "        node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_mxnet_style:\n",
    "    mx.viz.print_summary(\n",
    "        symbol,\n",
    "        shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "    )\n",
    "else:\n",
    "    mx.viz.print_summary(\n",
    "    net(mx.sym.var('data'))[1], \n",
    "    shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the weights \n",
    "(only needed if no pretrained weights are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a trainable module on compute context\n",
    "if use_mxnet_style:\n",
    "    model = mx.mod.Module(symbol=symbol, context=ctx, label_names=['value_label', 'policy_label'])\n",
    "    model.bind(for_training=True, data_shapes=[('data', (batch_size, input_shape[0], input_shape[1], input_shape[2]))],\n",
    "             label_shapes=val_iter.provide_label)\n",
    "    model.init_params(mx.initializer.Xavier(rnd_type='uniform', factor_type='avg', magnitude=2.24))\n",
    "    if params_file:\n",
    "        model.load_params(\"weights/\" + params_file)    \n",
    "else:\n",
    "    net.collect_params().initialize(mx.init.Xavier(rnd_type='uniform', factor_type='avg', magnitude=2.24), ctx=ctx)\n",
    "    net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_mxnet = [\n",
    "mx.metric.MSE(name='value_loss', output_names=['value_output'], label_names=['value_label']),\n",
    "mx.metric.CrossEntropy(name='policy_loss', output_names=['policy_output'],\n",
    "                                            label_names=['policy_label']),\n",
    "mx.metric.create(acc_sign, name='value_acc_sign', output_names=['value_output'],\n",
    "                                         label_names=['value_label']),\n",
    "mx.metric.Accuracy(axis=1, name='policy_acc', output_names=['policy_output'],\n",
    "                                       label_names=['policy_label'])\n",
    "]\n",
    "metrics_gluon = {\n",
    "'value_loss': mx.metric.MSE(name='value_loss', output_names=['value_output']),\n",
    "'policy_loss': mx.metric.CrossEntropy(name='policy_loss', output_names=['policy_output'],\n",
    "                                            label_names=['policy_label']),\n",
    "'value_acc_sign': mx.metric.create(acc_sign, name='value_acc_sign', output_names=['value_output'],\n",
    "                                         label_names=['value_label']),\n",
    "'policy_acc': mx.metric.Accuracy(axis=1, name='policy_acc', output_names=['policy_output'],\n",
    "                                       label_names=['policy_label'])\n",
    "}\n",
    "if use_mxnet_style:\n",
    "    metrics = metrics_mxnet\n",
    "else:\n",
    "    metrics = metrics_gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a training agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_mxnet_style:\n",
    "    train_agent = TrainerAgentMXNET(model, symbol, val_iter, nb_parts, lr_schedule, momentum_schedule, total_it, optimizer_name, wd=wd, batch_steps=batch_steps,\n",
    "                 k_steps_initial=k_steps_initial, cpu_count=CPU_COUNT-3, batch_size=batch_size, normalize=normalize, export_weights=export_weights,\n",
    "                 export_grad_histograms=export_grad_histograms, log_metrics_to_tensorboard=log_metrics_to_tensorboard, ctx=ctx, metrics=metrics,\n",
    "                use_spike_recovery=use_spike_recovery, max_spikes=max_spikes, spike_thresh=spike_thresh, seed=seed,\n",
    "                           val_loss_factor=val_loss_factor, policy_loss_factor=policy_loss_factor, select_policy_from_plane=select_policy_from_plane, discount=discount)\n",
    "else:\n",
    "    train_agent = TrainerAgent(net, val_data, nb_parts, lr_schedule, momentum_schedule, total_it, optimizer_name, wd=wd, batch_steps=batch_steps,\n",
    "                     k_steps_initial=k_steps_initial, cpu_count=CPU_COUNT-3, batch_size=batch_size, normalize=normalize, export_weights=export_weights,\n",
    "                     export_grad_histograms=export_grad_histograms, log_metrics_to_tensorboard=log_metrics_to_tensorboard, ctx=ctx, metrics=metrics,\n",
    "                    use_spike_recovery=use_spike_recovery, max_spikes=max_spikes, spike_thresh=spike_thresh, seed=seed,\n",
    "                               val_loss_factor=val_loss_factor, policy_loss_factor=policy_loss_factor, select_policy_from_plane=select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(val_iter, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adapted from: https://cwiki.apache.org/confluence/display/MXNET/How+to+use+MXNet-TensorRT+integration\n",
    "# Execute with MXNet\n",
    "x_batch = nd.array(x_val[0:128], ctx=ctx)\n",
    "batch_shape = (128, input_shape[0], input_shape[1], input_shape[2])\n",
    "if use_mxnet_style:\n",
    "    executor = symbol.simple_bind(ctx=mx.gpu(0), data=batch_shape, grad_req='null', force_rebind=True)\n",
    "    (arg_params, aux_params) = model.get_params()\n",
    "    executor.copy_params_from(arg_params, aux_params)\n",
    "\n",
    "    # Warmup\n",
    "    print('Warming up MXNet')\n",
    "    for i in range(0, 10):\n",
    "        y_gen = executor.forward(is_train=False, data=x_batch)\n",
    "        y_gen[0].wait_to_read()\n",
    "\n",
    "    # Timing\n",
    "    print('Starting MXNet timed run')\n",
    "    start = time()\n",
    "    for i in range(0, 500):\n",
    "        y_gen = executor.forward(is_train=False, data=x_batch)\n",
    "        y_gen[0].wait_to_read()\n",
    "    end = time()\n",
    "else:\n",
    "    # Warmup\n",
    "    print('Warming up MXNet')\n",
    "    for i in range(0, 10):\n",
    "        y_gen = net(x_batch)\n",
    "        y_gen[0][0].wait_to_read()\n",
    "\n",
    "    # Timing\n",
    "    print('Starting MXNet timed run')\n",
    "    start = time()\n",
    "    for i in range(0, 500):\n",
    "        y_gen = net(x_batch)\n",
    "        y_gen[0][0].wait_to_read()\n",
    "    end = time()\n",
    "print(\"Elapsed time: %.4fs\" % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(k_steps_final, val_loss_final, val_p_acc_final), (k_steps_best, val_loss_best, val_p_acc_best) = train_agent.train(cur_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the last model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"./weights/model-%.5f-%.3f\" % (val_loss_final, val_p_acc_final)\n",
    "\n",
    "if use_mxnet_style:\n",
    "    # the export function saves both the architecture and the weights\n",
    "    model.save_checkpoint(prefix, epoch=k_steps_final)\n",
    "else:\n",
    "    # the export function saves both the architecture and the weights\n",
    "    net.export(prefix, epoch=k_steps_final)\n",
    "    logging.info(\"Saved checkpoint to %s-%04d.params\", prefix, k_steps_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete the current net object form memory\n",
    "if not use_mxnet_style:\n",
    "    del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = \"./weights/model-%.5f-%.3f\" % (val_loss_best, val_p_acc_best)\n",
    "model_arch_path = '%s-symbol.json' % model_prefix\n",
    "model_params_path = '%s-%04d.params' % (model_prefix, k_steps_best)\n",
    "print('load current best model:', model_params_path)\n",
    "symbol = mx.sym.load(model_arch_path)\n",
    "inputs = mx.sym.var('data', dtype='float32')\n",
    "value_out = symbol.get_internals()['value_out_output'] #value_out_output']\n",
    "policy_out = symbol.get_internals()['policy_out_output']\n",
    "sym = mx.symbol.Group([value_out, policy_out])\n",
    "net = mx.gluon.SymbolBlock(sym, inputs)\n",
    "net.collect_params().load(model_params_path, ctx) #, allow_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best val_loss: %.5f with v_policy_acc: %.5f at k_steps_best %d' % (val_loss_best, val_p_acc_best, k_steps_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = planes_to_board(x_val[idx], normalized_input=normalize)\n",
    "\n",
    "print(chess.COLOR_NAMES[board.turn])\n",
    "if board.uci_variant == \"crazyhouse\":\n",
    "    print(board.pockets)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_single(net, x, select_policy_from_plane=False):\n",
    "    \n",
    "    out = [None, None]\n",
    "    pred = net(mx.nd.array(np.expand_dims(x, axis=0), ctx=ctx))\n",
    "    if select_policy_from_plane:\n",
    "        pred[1] = pred[1][:, FLAT_PLANE_IDX]\n",
    "    pred[1] = pred[1].softmax()\n",
    "    out[0] = pred[0].asnumpy()\n",
    "    out[1] = pred[1].asnumpy()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_single(net, x_val[0], select_policy_from_plane)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = predict_single(net, x_val[0], select_policy_from_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_to_best_move(board, yp_val[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = 5\n",
    "selected_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "selected_moves[:opts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(opts)[::-1], probs[:opts])\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(opts)[::-1])\n",
    "ax.set_yticklabels(selected_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "board = planes_to_board(x_val[0], normalized_input=True)\n",
    "board.push_uci('e2e4')\n",
    "board.push_uci('e7e5')\n",
    "board.push_uci('f1c4')\n",
    "board.push_uci('b8c6')\n",
    "board.push_uci('d1h5')\n",
    "x_scholar_atck = board_to_planes(board, normalize=normalize)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = predict_single(net, x_scholar_atck, select_policy_from_plane)\n",
    "\n",
    "selected_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "plt.barh(range(opts)[::-1], probs[:opts])\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(opts)[::-1])\n",
    "ax.set_yticklabels(selected_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "board.push(selected_moves[0])\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idcs_test, x_test, yv_test, yp_test, _, pgn_datasets_test = load_pgn_dataset(dataset_type='test', part_id=0,\n",
    "                                                                           print_statistics=True, print_parameters=True, normalize=True)\n",
    "test_dataset = gluon.data.ArrayDataset(nd.array(x_test), nd.array(yv_test), nd.array(yp_test.argmax(axis=1)))\n",
    "test_data = gluon.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics_gluon\n",
    "evaluate_metrics(metrics, test_data, net, nb_batches=None, select_policy_from_plane=select_policy_from_plane, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show result on mate-in-one problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_idcs_mate, x_mate, yv_mate, yp_mate, _, pgn_dataset_mate = load_pgn_dataset(dataset_type='mate_in_one', part_id=1,\n",
    "                                                         print_parameters=True, print_statistics=True, normalize=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mate_dataset = mx.gluon.data.dataset.ArrayDataset(nd.array(x_mate), nd.array(yv_mate), nd.array(yp_mate.argmax(axis=1)))\n",
    "mate_data = mx.gluon.data.DataLoader(mate_dataset, batch_size=batch_size, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mate In One Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_metrics(metrics, mate_data, net, select_policy_from_plane=select_policy_from_plane, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some example mate problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_pos(net, x_mate, yp_mate, verbose=False, select_policy_from_plane=False):\n",
    "    \n",
    "    board = planes_to_board(x_mate, normalized_input=normalize)\n",
    "    if verbose is True:\n",
    "        print(\"{0}'s turn\".format(chess.COLOR_NAMES[board.turn]))\n",
    "        if board.uci_variant == \"crazyhouse\":\n",
    "            print(\"black/white {0}\".format(board.pockets))\n",
    "    pred = predict_single(net, x_mate, select_policy_from_plane=select_policy_from_plane)\n",
    "    \n",
    "    true_move = policy_to_move(yp_mate, is_white_to_move=board.turn)\n",
    "    \n",
    "    opts = 5\n",
    "    pred_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "    pred_moves = pred_moves[:opts]\n",
    "    \n",
    "    legal_move_cnt = board.legal_moves.count()\n",
    "    mate_move_cnt = str(board.legal_moves).count('#')\n",
    "    \n",
    "    is_mate_5_top = False\n",
    "    \n",
    "    for pred_move in pred_moves:\n",
    "        board_5_top = deepcopy(board)\n",
    "        board_5_top.push(pred_move)\n",
    "        if board_5_top.is_checkmate() is True:\n",
    "            is_mate_5_top = True\n",
    "            break\n",
    "    \n",
    "    board.push(pred_moves[0])\n",
    "    \n",
    "    is_checkmate = False\n",
    "    if board.is_checkmate() is True:\n",
    "        is_checkmate = True\n",
    "        \n",
    "    filtered_pred = sorted(pred[1][0], reverse=True)\n",
    "    \n",
    "    if verbose is True:\n",
    "        plt.barh(range(opts)[::-1], filtered_pred[:opts])\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks(range(opts)[::-1])\n",
    "        ax.set_yticklabels(pred_moves)\n",
    "        plt.title('True Move:' + str(true_move) +\n",
    "                 '\\nEval:' + str(pred[0][0]))\n",
    "        plt.show()\n",
    "    \n",
    "    return pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_pos = len(x_mate)\n",
    "mates_found = []\n",
    "mates_5_top_found = []\n",
    "legal_mv_cnts = []\n",
    "mate_mv_cnts = []\n",
    "\n",
    "for i in range(nb_pos):\n",
    "    pred, pred_moves, true_move, board, is_mate, is_mate_5_top, legal_mv_cnt, mate_mv_cnt= eval_pos(net, x_mate[i], yp_mate[i], select_policy_from_plane=select_policy_from_plane)\n",
    "    mates_found.append(is_mate)\n",
    "    legal_mv_cnts.append(legal_mv_cnt)\n",
    "    mate_mv_cnts.append(mate_mv_cnt)\n",
    "    mates_5_top_found.append(is_mate_5_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(mate_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(legal_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Guessing Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(mate_mv_cnts).mean() / np.array(legal_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('mate_in_one_acc:', sum(mates_found) / nb_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(mates_5_top_found) / nb_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pgn_dataset_mate.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = np.array(pgn_dataset_mate['metadata'])\n",
    "metadata[0, :]\n",
    "metadata[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_mate = metadata[1:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_string(np_string):\n",
    "    string = str(site_mate[i]).replace(\"b'\", \"\")\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    string = string.replace('\"', '')\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chess.svg\n",
    "from IPython.display import SVG, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the result of the first 17 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(17):\n",
    "    print(clean_string(site_mate[i]))\n",
    "    pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=True, select_policy_from_plane=select_policy_from_plane)\n",
    "    pred_move = pred_moves[0]\n",
    "    pred_arrow = chess.svg.Arrow(pred_move.from_square, pred_move.to_square)\n",
    "    SVG(data=chess.svg.board(board=board, arrows=[pred_arrow], size=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show examples where it failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=False, select_policy_from_plane=select_policy_from_plane)\n",
    "    if is_mate_5_top is False:\n",
    "        print(clean_string(site_mate[i]))\n",
    "        pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=True, select_policy_from_plane=select_policy_from_plane)\n",
    "        pred_move = pred_moves[0]\n",
    "        pred_arrow = chess.svg.Arrow(pred_move.from_square, pred_move.to_square)\n",
    "        SVG(data=chess.svg.board(board=board, arrows=[pred_arrow], size=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
